{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deskrispi Data :\n",
    "\n",
    "    CustomerName : Nama \n",
    "    Age :   umur\n",
    "    MaritalStatus : (0) =  Belum Menikah \n",
    "                    (1) = Sudah Menikah\n",
    "    IncomeRange : ---\n",
    "    Gender  : (0) = Laki- Laki \n",
    "            (1) = Perempuan\n",
    "    TotalChildren:  ---\n",
    "    ChildrenAtHome : ---\n",
    "    Education : (0) = SMA\n",
    "                (1) = S1\n",
    "                (2) = Post Graduate\n",
    "                (3) = S2\n",
    "                (4) =  S3\n",
    "    Occupation :    (0) = sales\n",
    "                    (1) = skilled manual work\n",
    "                    (2) = unskilled manual work\n",
    "                    (3) = professional\n",
    "                    (4) = clerical work \n",
    "                    (5) = management\n",
    "    HomeOwner : (0) = tidak memiliki  rumah  sendiri\n",
    "                (1) = memiliki rumah sendiri\n",
    "    Cars  :   ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "appName = \"Klastering di Spark\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+---+-------------+-----------+------+-------------+--------------+---------+----------+---------+----+\n",
      "|_c0|    CustomerName|Age|MaritalStatus|IncomeRange|Gender|TotalChildren|ChildrenAtHome|Education|Occupation|HomeOwner|Cars|\n",
      "+---+----------------+---+-------------+-----------+------+-------------+--------------+---------+----------+---------+----+\n",
      "|  0|      Wati Putra| 69|            0|     110527|     1|            4|             4|        4|         2|        0|   0|\n",
      "|  1|Cahyadi Haryanto| 63|            1|     125609|     0|            0|             5|        1|         1|        1|   0|\n",
      "+---+----------------+---+-------------+-----------+------+-------------+--------------+---------+----------+---------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers = spark.read.csv(\n",
    "    'D:\\SEKOLAH\\KULIAH\\SEMESTER 6\\PENAMBANGAN DATA\\Clustering K-Means\\clean_customer_data_6.csv', inferSchema=True, header=True)\n",
    "customers.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------------------------------------+\n",
      "|CustomerName    |features                                       |\n",
      "+----------------+-----------------------------------------------+\n",
      "|Wati Putra      |[69.0,0.0,110527.0,1.0,4.0,4.0,4.0,2.0,0.0,0.0]|\n",
      "|Cahyadi Haryanto|[63.0,1.0,125609.0,0.0,0.0,5.0,1.0,1.0,1.0,0.0]|\n",
      "+----------------+-----------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols = [\n",
    "    \"Age\", \"MaritalStatus\", \"IncomeRange\", \"Gender\", \"TotalChildren\",\n",
    "    \"ChildrenAtHome\", \"Education\", \"Occupation\", \"HomeOwner\", \"Cars\"],\n",
    "                            outputCol=\"features\")\n",
    "train = assembler.transform(customers).select('CustomerName', 'features')\n",
    "train.show(truncate = False, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model selesai dibuat!\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(\n",
    "    featuresCol=assembler.getOutputCol(), predictionCol=\"cluster\",\n",
    "    k=5, seed=0)\n",
    "model = kmeans.fit(train)\n",
    "print (\"Model selesai dibuat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[4.38759058e+01 5.08152174e-01 1.36054785e+05 5.01358696e-01\n",
      " 2.51675725e+00 1.25860507e+00 1.98958333e+00 2.50815217e+00\n",
      " 4.81431159e-01 1.52898551e+00]\n",
      "[4.38693416e+01 5.01543210e-01 3.26506199e+04 5.20061728e-01\n",
      " 2.51388889e+00 1.23713992e+00 1.97067901e+00 2.50102881e+00\n",
      " 4.95884774e-01 1.51646091e+00]\n",
      "[4.31859244e+01 5.10504202e-01 8.40943634e+04 4.94747899e-01\n",
      " 2.45535714e+00 1.28151261e+00 2.00157563e+00 2.49002101e+00\n",
      " 5.01050420e-01 1.46638655e+00]\n",
      "[4.31295732e+01 4.98475610e-01 5.81993582e+04 4.90853659e-01\n",
      " 2.49491870e+00 1.25965447e+00 1.96138211e+00 2.42225610e+00\n",
      " 4.88313008e-01 1.48780488e+00]\n",
      "[4.30288462e+01 5.05060729e-01 1.09898108e+05 4.92914980e-01\n",
      " 2.52732794e+00 1.22115385e+00 1.97975709e+00 2.45242915e+00\n",
      " 5.12145749e-01 1.48937247e+00]\n"
     ]
    }
   ],
   "source": [
    "centers = model.clusterCenters() \n",
    "print(\"Cluster Centers: \") \n",
    "for center in centers: \n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|cluster|count|\n",
      "+-------+-----+\n",
      "|      0| 2201|\n",
      "|      1| 1952|\n",
      "|      2| 1910|\n",
      "|      3| 1968|\n",
      "|      4| 1969|\n",
      "+-------+-----+\n",
      "\n",
      "+----------------+-------+\n",
      "|    CustomerName|cluster|\n",
      "+----------------+-------+\n",
      "|      Wati Putra|      4|\n",
      "|Cahyadi Haryanto|      0|\n",
      "|    Maya Pratama|      1|\n",
      "|    Zainab Hakim|      2|\n",
      "|    Wati Pratama|      1|\n",
      "|     Lina Fauzan|      1|\n",
      "|    Maya Rachman|      4|\n",
      "|   Siti Muliawan|      1|\n",
      "|Zainab Anggraini|      3|\n",
      "|   Fitri Santoso|      3|\n",
      "|Cahyadi Haryanto|      3|\n",
      "|    Budi Santoso|      0|\n",
      "|  Wati Anggraini|      1|\n",
      "|    Joko Purnomo|      0|\n",
      "|    Indra Fauzan|      3|\n",
      "|    Dewi Saputra|      0|\n",
      "|      Lina Utomo|      1|\n",
      "|     Eko Santoso|      1|\n",
      "|   Maya Setiawan|      1|\n",
      "|    Rizki Fauzan|      0|\n",
      "+----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(train)#melakukan prediksi klaster\n",
    "prediction.groupBy(\"cluster\").count().orderBy(\"cluster\").show()\n",
    "prediction.select('CustomerName', 'cluster').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-------+\n",
      "|    CustomerName|            features|cluster|\n",
      "+----------------+--------------------+-------+\n",
      "|      Wati Putra|[69.0,0.0,110527....|      4|\n",
      "|Cahyadi Haryanto|[63.0,1.0,125609....|      0|\n",
      "|    Maya Pratama|[22.0,0.0,43943.0...|      1|\n",
      "|    Zainab Hakim|[69.0,1.0,85893.0...|      2|\n",
      "|    Wati Pratama|[44.0,0.0,43524.0...|      1|\n",
      "|     Lina Fauzan|[24.0,1.0,24980.0...|      1|\n",
      "|    Maya Rachman|[68.0,1.0,111260....|      4|\n",
      "|   Siti Muliawan|[63.0,0.0,44985.0...|      1|\n",
      "|Zainab Anggraini|[33.0,1.0,46491.0...|      3|\n",
      "|   Fitri Santoso|[57.0,0.0,55478.0...|      3|\n",
      "|Cahyadi Haryanto|[20.0,1.0,50115.0...|      3|\n",
      "|    Budi Santoso|[28.0,0.0,126194....|      0|\n",
      "|  Wati Anggraini|[67.0,0.0,34471.0...|      1|\n",
      "|    Joko Purnomo|[48.0,0.0,147860....|      0|\n",
      "|    Indra Fauzan|[38.0,0.0,66408.0...|      3|\n",
      "|    Dewi Saputra|[62.0,1.0,136252....|      0|\n",
      "|      Lina Utomo|[42.0,1.0,26724.0...|      1|\n",
      "|     Eko Santoso|[27.0,1.0,21578.0...|      1|\n",
      "|   Maya Setiawan|[28.0,1.0,27239.0...|      1|\n",
      "|    Rizki Fauzan|[69.0,1.0,131249....|      0|\n",
      "+----------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = prediction['features','cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|cluster|\n",
      "+--------------------+-------+\n",
      "|[69.0,0.0,110527....|      4|\n",
      "|[63.0,1.0,125609....|      0|\n",
      "|[22.0,0.0,43943.0...|      1|\n",
      "|[69.0,1.0,85893.0...|      2|\n",
      "|[44.0,0.0,43524.0...|      1|\n",
      "|[24.0,1.0,24980.0...|      1|\n",
      "|[68.0,1.0,111260....|      4|\n",
      "|[63.0,0.0,44985.0...|      1|\n",
      "|[33.0,1.0,46491.0...|      3|\n",
      "|[57.0,0.0,55478.0...|      3|\n",
      "|[20.0,1.0,50115.0...|      3|\n",
      "|[28.0,0.0,126194....|      0|\n",
      "|[67.0,0.0,34471.0...|      1|\n",
      "|[48.0,0.0,147860....|      0|\n",
      "|[38.0,0.0,66408.0...|      3|\n",
      "|[62.0,1.0,136252....|      0|\n",
      "|[42.0,1.0,26724.0...|      1|\n",
      "|[27.0,1.0,21578.0...|      1|\n",
      "|[28.0,1.0,27239.0...|      1|\n",
      "|[69.0,1.0,131249....|      0|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = new_df.randomSplit([0.8,0.2],seed =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"cluster\", featuresCol=\"features\", numTrees=10)\n",
    "nv = NaiveBayes(labelCol='cluster',featuresCol='features' )\n",
    "\n",
    "# Train the model\n",
    "model = rf.fit(train_df)\n",
    "model_nv = nv.fit(train_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+\n",
      "|            features|cluster|prediction|\n",
      "+--------------------+-------+----------+\n",
      "|(10,[0,1,2,3,4],[...|      1|       1.0|\n",
      "|(10,[0,1,2,3,7],[...|      0|       0.0|\n",
      "|(10,[0,1,2,3,8],[...|      0|       0.0|\n",
      "|(10,[0,1,2,4,5],[...|      3|       3.0|\n",
      "|(10,[0,1,2,4,6],[...|      4|       4.0|\n",
      "|(10,[0,1,2,4,6],[...|      0|       0.0|\n",
      "|(10,[0,1,2,4,7],[...|      3|       3.0|\n",
      "|(10,[0,1,2,4,7],[...|      3|       3.0|\n",
      "|(10,[0,1,2,4,9],[...|      1|       1.0|\n",
      "|(10,[0,1,2,4,9],[...|      0|       0.0|\n",
      "|(10,[0,1,2,4,9],[...|      4|       4.0|\n",
      "|(10,[0,1,2,4,9],[...|      0|       0.0|\n",
      "|(10,[0,1,2,4,9],[...|      4|       4.0|\n",
      "|(10,[0,1,2,5,6],[...|      0|       0.0|\n",
      "|(10,[0,1,2,5,7],[...|      1|       1.0|\n",
      "|(10,[0,1,2,5,9],[...|      4|       4.0|\n",
      "|(10,[0,1,2,6,7],[...|      4|       4.0|\n",
      "|(10,[0,1,2,7,9],[...|      2|       2.0|\n",
      "|(10,[0,1,2,8,9],[...|      4|       4.0|\n",
      "|(10,[0,2,3],[66.0...|      3|       3.0|\n",
      "+--------------------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-------+----------+\n",
      "|            features|cluster|prediction|\n",
      "+--------------------+-------+----------+\n",
      "|(10,[0,1,2,3,4],[...|      1|       1.0|\n",
      "|(10,[0,1,2,3,7],[...|      0|       0.0|\n",
      "|(10,[0,1,2,3,8],[...|      0|       0.0|\n",
      "|(10,[0,1,2,4,5],[...|      3|       2.0|\n",
      "|(10,[0,1,2,4,6],[...|      4|       0.0|\n",
      "|(10,[0,1,2,4,6],[...|      0|       0.0|\n",
      "|(10,[0,1,2,4,7],[...|      3|       2.0|\n",
      "|(10,[0,1,2,4,7],[...|      3|       3.0|\n",
      "|(10,[0,1,2,4,9],[...|      1|       1.0|\n",
      "|(10,[0,1,2,4,9],[...|      0|       0.0|\n",
      "|(10,[0,1,2,4,9],[...|      4|       0.0|\n",
      "|(10,[0,1,2,4,9],[...|      0|       0.0|\n",
      "|(10,[0,1,2,4,9],[...|      4|       4.0|\n",
      "|(10,[0,1,2,5,6],[...|      0|       0.0|\n",
      "|(10,[0,1,2,5,7],[...|      1|       1.0|\n",
      "|(10,[0,1,2,5,9],[...|      4|       2.0|\n",
      "|(10,[0,1,2,6,7],[...|      4|       0.0|\n",
      "|(10,[0,1,2,7,9],[...|      2|       0.0|\n",
      "|(10,[0,1,2,8,9],[...|      4|       4.0|\n",
      "|(10,[0,2,3],[66.0...|      3|       3.0|\n",
      "+--------------------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "predictions_nv = model_nv.transform(test_df)\n",
    "predictions.select(\"features\", \"cluster\", \"prediction\").show()\n",
    "predictions_nv.select(\"features\", \"cluster\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy random forest : 0.9448204060385216\n",
      "Test Accuracy Naive Bayes : 0.5111920874544508\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy_nv = evaluator.evaluate(predictions_nv)\n",
    "print(f\"Test Accuracy random forest : {accuracy}\")\n",
    "print(f\"Test Accuracy Naive Bayes : {accuracy_nv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
